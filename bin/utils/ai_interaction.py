import openai
import os
from dotenv import load_dotenv
import res.const as const
from bin.utils.misc import num_tokens_from_messages
from timeout_decorator import timeout

# Set your API key
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

def convert_audio_to_text(audio_file_path) -> str:
    audio_file= open(audio_file_path, "rb")
    transcript = openai.Audio.transcribe("whisper-1", audio_file)
    return transcript['text']

def compress_history(history):
    """Consolidates history into a single string generated by the ai"""
    print("History Too Long, Consolidating Messages")
    recent = history[-1]
    #history.append({"role": "system", "content": "In as little words as possible, please summarize the conversation so far."})
    history.append({"role": "system", "content": """
    Step 1, Get rid of all the unnecessary formatting and information.
    Step 2, Delete all content that are not relevant to the current conversation / question.
    Step 3, Create a short summary of the information that has been discussed so far in a short bulleted list.
    Include who said what, and make sure to keep specifics of information that pertains to the
    recent parts of the conversation and the possible question asked.
    Be sure to make the summary as short as possible."""})
    response = generate_response(history=history, personality=False, ignore_token_limit=True)
    # remove all messages from history
    history.clear()
    history.append({"role": "system", "content": "A summary of the conversation: " + response })
    history.append(recent)

# Define function to generate response
@timeout(30, timeout_exception=TimeoutError)
def generate_response(model="gpt-3.5-turbo", history=[], personality=True, ignore_token_limit=False):
    # is_truncated = False
    try:
        if not ignore_token_limit:
            # while num_tokens_from_messages(history) > compression_threshold:
                # get rid of oldest message
                # print("History Too Long, Removing Oldest Message")
                # history.pop()
                # is_truncated = True
            if num_tokens_from_messages(history) > const.COMPRESSION_THRESHOLD:
                compress_history(history)

        
        # add {} to the top of history
        if personality:
            history.insert(0, {"role": "system", "content": const.BOT_PERSONALITY})
        
        response = openai.ChatCompletion.create(
            model=model,
            messages=history
        )
        response = response["choices"][0]["message"]["content"]
        # remove the personality from the history, saving space
        if personality:
            history.pop(0)
        # if is_truncated:
        #     response = "**History too long, some messages have been removed.\n**" + response
        return response 
    except Exception as e:
        print(e)
        return str(e)
    
def generate_image(prompt):
    try:
        response = openai.Image.create(
            prompt=prompt,
            n=1,
            size="1024x1024"
        )
        image_url = response['data'][0]['url']
        return image_url
    except Exception as e:
        print(e)

def is_known(history) -> bool:
    """Checks if the message is known to the ai
    If it responds with const.STATEMENT, it is a statement | return true
    If it responds with const.CONTEXT, it is a known question | return true
        else, forms a google query | return false
    If it responds with const.TIME_BOUND, it is a time bound question | return false
    If it responds with const.UNKNOWN_ANSWER, it is an unknown question | return false"""
    # # Check if its a statement
    # history.append({"role": "system", "content": "If the users prompt is a statement, respond with only the words, 'const.STATEMENT'. Otherwise, respond with only the words, 'const.QUESTION'."})
    # response = generate_response(history=history, personality=False)
    # history.pop()
    # print(response)
    # if 'const.STATEMENT' in response:
    #     print('statement')
    #     return True

    # # Check if relates to context
    # history.append({"role": "system", "content": "If the information requested by the user is found within the message history, respond with only the words, 'const.CONTEXT'. Else, respond with a google query that will return the information requested."})
    # response = generate_response(history=history, personality=False)
    # history.pop()
    # print(response)
    # if not 'const.CONTEXT' in response:
    #     # create new google query based on context
    #     history.append({"role": "user", "content": response})
    #     print('no context')
    #     return False

    history.append({"role": "user", "content": "If what was asked might change with time, or could have happened after 2020, respond with only the words, 'const.TIME_BOUND'. otherwise, respond with only the word, 'word'"})
    response = generate_response(history=history, personality=False)
    history.pop()
    print(response)
    if 'const.TIME_BOUND' in response:
        print('time bound')
        return False
    
    #check if question
    history.append({"role": "user", "content": "If the users prompt is a question that you can answer with your dataset, capped in 2020, respond with only the words, 'const.QUESTION'. otherwise, respond with only the word, 'word'"})
    response = generate_response(history=history, personality=False)
    history.pop()
    print(response)
    if 'const.QUESTION' in response:
        print('question')
        return True

    history.append({"role": "user", "content": "If the question asked requires searching the internet and cannot be answered with conversation context, simply respond with only the words, 'const.UNKNOWN_ANSWER'. otherwise, respond with only the word, 'word'"})
    response = generate_response(history=history, personality=False)
    history.pop()
    print(response)
    if 'const.UNKNOWN_ANSWER' in response:
        print('unknown')
        return False
    return True

# Define function to run the chatbot
def query(prompt='', history=[], personality=True):
    if prompt != '':
        history.append({"role":"user", "content":prompt})
    return generate_response(history=history, personality=personality)

def query_image(prompt):
    return generate_image(prompt)

def test_audio():
    print(convert_audio_to_text("test_files/hungry.wav"))

if __name__ == "__main__":
    pass